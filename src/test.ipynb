{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, LSTM, Dense, Input, Masking, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from PIL import Image\n",
    "from torchinfo import summary \n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetFeatureExtractor, self).__init__()\n",
    "        resnet = models.resnet18(weights='IMAGENET1K_V1')\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
    "\n",
    "        for param in self.features[-2:].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        return features.mean([2, 3])\n",
    "\n",
    "class AttentionModule(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(AttentionModule, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_size * 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = self.attention(x) \n",
    "        weights = torch.softmax(scores, dim=1)\n",
    "        context = (x * weights).sum(dim=1)\n",
    "        return context\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True,\n",
    "                            dropout=0.45)\n",
    "        self.attention = AttentionModule(hidden_size)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        context = self.attention(lstm_out)\n",
    "        output = self.classifier(context)\n",
    "        return output\n",
    "\n",
    "class SequenceClassificationModel(nn.Module):\n",
    "    def __init__(self, lstm_hidden_size=512, lstm_num_layers=2):\n",
    "        super(SequenceClassificationModel, self).__init__()\n",
    "        self.feature_extractor = ResNetFeatureExtractor()\n",
    "        self.sequence_classifier = LSTMClassifier(input_size=512, \n",
    "                                                  hidden_size=lstm_hidden_size,\n",
    "                                                  num_layers=lstm_num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, c, h, w = x.size()\n",
    "        x = x.view(batch_size * seq_len, c, h, w)\n",
    "        features = self.feature_extractor(x)  \n",
    "        features = features.view(batch_size, seq_len, -1)\n",
    "        output = self.sequence_classifier(features)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_5912\\2673338135.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"model_f1_0.7682.pth\")\n",
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_5912\\2673338135.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"model_f1_complete.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassificationModel(\n",
       "  (feature_extractor): ResNetFeatureExtractor(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (sequence_classifier): LSTMClassifier(\n",
       "    (lstm): LSTM(512, 512, num_layers=2, batch_first=True, dropout=0.45, bidirectional=True)\n",
       "    (attention): AttentionModule(\n",
       "      (attention): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.3, inplace=False)\n",
       "      (3): Linear(in_features=256, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"model_f1_0.7682.pth\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../Advanced-MRI-Breast-Lesions-DA-Clinical-Jan112024.csv'\n",
    "dataDirectory = \"../../Data/Advanced-MRI-Breast-Lesions\"\n",
    "separador = \"=\" * 100\n",
    "\n",
    "excluded_implants = [\n",
    "    'AMBL-002', 'AMBL-004', 'AMBL-015', 'AMBL-027',\n",
    "    'AMBL-049', 'AMBL-566', 'AMBL-585', 'AMBL-592',\n",
    "    'AMBL-617', 'AMBL-618', 'AMBL-620', 'AMBL-624',\n",
    "    'AMBL-626']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = pd.read_csv(file_path, sep=';', skiprows=1)[['Patient ID', 'BIRADS']].dropna()\n",
    "subfolders_ids = [folder for folder in os.listdir(dataDirectory) if os.path.isdir(os.path.join(dataDirectory, folder))]\n",
    "df_subset = df_subset[~df_subset['Patient ID'].isin(excluded_implants)]\n",
    "birads_replacements = {'-1': '0', '4A': '4', '3, 4A': '4'}\n",
    "df_subset['BIRADS'] = df_subset['BIRADS'].replace(birads_replacements).astype(int)\n",
    "df_subset = df_subset[df_subset['BIRADS'] != 0]\n",
    "df_subset = df_subset[df_subset['Patient ID'].astype(str).isin(subfolders_ids)]\n",
    "df_subset['malignant'] = (df_subset['BIRADS'] > 3).astype(int)\n",
    "amount_pacients = len(df_subset)\n",
    "birads_group_frequencies = df_subset['malignant'].value_counts().sort_index()\n",
    "frequencies_table_grouped = pd.DataFrame({\n",
    "    'Malignant': birads_group_frequencies.index,\n",
    "    'Frecuencia': birads_group_frequencies.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Tipo de BIRADS antes de la modificación: int32\n",
      "Valores únicos de BIRADS antes de la modificación: [4 6 2 3 5 1]\n",
      "====================================================================================================\n",
      "Tipo de BIRADS después de la conversión: int32\n",
      "Valores únicos de BIRADS: [4 6 2 3 5 1]\n",
      "====================================================================================================\n",
      "Dimensiones de los datos: (185, 3)\n",
      "====================================================================================================\n",
      "   Malignant  Frecuencia\n",
      "0          0          62\n",
      "1          1         123\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(separador)\n",
    "print(\"Tipo de BIRADS antes de la modificación:\", df_subset['BIRADS'].dtype)\n",
    "print(\"Valores únicos de BIRADS antes de la modificación:\", df_subset['BIRADS'].unique())\n",
    "print(separador)\n",
    "print(\"Tipo de BIRADS después de la conversión:\", df_subset['BIRADS'].dtype)\n",
    "print(\"Valores únicos de BIRADS:\", df_subset['BIRADS'].unique())\n",
    "print(separador)\n",
    "print(f'Dimensiones de los datos: {df_subset.shape}')\n",
    "print(separador)\n",
    "print(frequencies_table_grouped)\n",
    "print(separador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_image(file_path):\n",
    "    try:\n",
    "        dicom = pydicom.dcmread(file_path)\n",
    "        if not hasattr(dicom, \"pixel_array\"):\n",
    "            raise ValueError(f\"El archivo {file_path} no contiene datos de imagen.\")\n",
    "        image = dicom.pixel_array.astype(np.float32)\n",
    "        intercept = getattr(dicom, \"RescaleIntercept\", 0)\n",
    "        slope = getattr(dicom, \"RescaleSlope\", 1)\n",
    "        image = image * slope + intercept\n",
    "        return image\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar la imagen DICOM ({file_path}): {e}\")\n",
    "        return None\n",
    "\n",
    "def normalize_for_resnet(image):\n",
    "    p25, p95 = np.percentile(image, (25, 95))\n",
    "    image = np.clip(image, p25, p95)\n",
    "\n",
    "    if image.max() == image.min():\n",
    "        image = np.zeros_like(image)\n",
    "    else:\n",
    "        image = (image - image.min()) / (image.max() - image.min())\n",
    "\n",
    "    image_tensor = torch.tensor(image, dtype=torch.float32).unsqueeze(0)\n",
    "    image_tensor = image_tensor.repeat(3, 1, 1)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreastCancerDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None, minority_transform=None, max_images=116, image_size=224):\n",
    "        self.dataframe = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = test_transform\n",
    "        self.minority_transform = test_transform\n",
    "        self.max_images = max_images\n",
    "        self.to_pil = ToPILImage()\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.dataframe.iloc[idx]['Patient ID']\n",
    "        label = self.dataframe.iloc[idx]['malignant']\n",
    "        patient_dir = os.path.join(self.root_dir, patient_id)\n",
    "        \n",
    "        dicom_files = sorted([f for f in os.listdir(patient_dir) if f.endswith('.dcm')])\n",
    "\n",
    "        images = []\n",
    "        for file in dicom_files[:self.max_images]:\n",
    "            image_path = os.path.join(patient_dir, file)\n",
    "\n",
    "            image = load_dicom_image(image_path)\n",
    "            if image is not None:\n",
    "                image = normalize_for_resnet(image)\n",
    "                image = self.to_pil(image)\n",
    "                if self.minority_transform and label == 0:\n",
    "                    image = self.minority_transform(image)\n",
    "                elif self.transform:\n",
    "                    image = self.transform(image)\n",
    "\n",
    "                images.append(image)\n",
    "\n",
    "        sequence_length = len(images)\n",
    "\n",
    "        if len(images) == 0:\n",
    "            placeholder_image = torch.zeros((3, self.image_size, self.image_size))\n",
    "            images = [placeholder_image] * self.max_images\n",
    "        while len(images) < self.max_images:\n",
    "            images.append(torch.zeros_like(images[0]))\n",
    "\n",
    "        images_tensor = torch.stack(images)\n",
    "        return images_tensor, sequence_length, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BreastCancerDataset(dataframe=df_subset, root_dir=dataDirectory, transform=test_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Inicializar las listas para las métricas\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando lote 1/185...\n",
      "Quedan 184 lotes.\n",
      "Procesando lote 2/185...\n",
      "Quedan 183 lotes.\n",
      "Procesando lote 3/185...\n",
      "Quedan 182 lotes.\n",
      "Procesando lote 4/185...\n",
      "Quedan 181 lotes.\n",
      "Procesando lote 5/185...\n",
      "Quedan 180 lotes.\n",
      "Procesando lote 6/185...\n",
      "Quedan 179 lotes.\n",
      "Procesando lote 7/185...\n",
      "Quedan 178 lotes.\n",
      "Procesando lote 8/185...\n",
      "Quedan 177 lotes.\n",
      "Procesando lote 9/185...\n",
      "Quedan 176 lotes.\n",
      "Procesando lote 10/185...\n",
      "Quedan 175 lotes.\n",
      "Procesando lote 11/185...\n",
      "Quedan 174 lotes.\n",
      "Procesando lote 12/185...\n",
      "Quedan 173 lotes.\n",
      "Procesando lote 13/185...\n",
      "Quedan 172 lotes.\n",
      "Procesando lote 14/185...\n",
      "Quedan 171 lotes.\n",
      "Procesando lote 15/185...\n",
      "Quedan 170 lotes.\n",
      "Procesando lote 16/185...\n",
      "Quedan 169 lotes.\n",
      "Procesando lote 17/185...\n",
      "Quedan 168 lotes.\n",
      "Procesando lote 18/185...\n",
      "Quedan 167 lotes.\n",
      "Procesando lote 19/185...\n",
      "Quedan 166 lotes.\n",
      "Procesando lote 20/185...\n",
      "Quedan 165 lotes.\n",
      "Procesando lote 21/185...\n",
      "Quedan 164 lotes.\n",
      "Procesando lote 22/185...\n",
      "Quedan 163 lotes.\n",
      "Procesando lote 23/185...\n",
      "Quedan 162 lotes.\n",
      "Procesando lote 24/185...\n",
      "Quedan 161 lotes.\n",
      "Procesando lote 25/185...\n",
      "Quedan 160 lotes.\n",
      "Procesando lote 26/185...\n",
      "Quedan 159 lotes.\n",
      "Procesando lote 27/185...\n",
      "Quedan 158 lotes.\n",
      "Procesando lote 28/185...\n",
      "Quedan 157 lotes.\n",
      "Procesando lote 29/185...\n",
      "Quedan 156 lotes.\n",
      "Procesando lote 30/185...\n",
      "Quedan 155 lotes.\n",
      "Procesando lote 31/185...\n",
      "Quedan 154 lotes.\n",
      "Procesando lote 32/185...\n",
      "Quedan 153 lotes.\n",
      "Procesando lote 33/185...\n",
      "Quedan 152 lotes.\n",
      "Procesando lote 34/185...\n",
      "Quedan 151 lotes.\n",
      "Procesando lote 35/185...\n",
      "Quedan 150 lotes.\n",
      "Procesando lote 36/185...\n",
      "Quedan 149 lotes.\n",
      "Procesando lote 37/185...\n",
      "Quedan 148 lotes.\n",
      "Procesando lote 38/185...\n",
      "Quedan 147 lotes.\n",
      "Procesando lote 39/185...\n",
      "Quedan 146 lotes.\n",
      "Procesando lote 40/185...\n",
      "Quedan 145 lotes.\n",
      "Procesando lote 41/185...\n",
      "Quedan 144 lotes.\n",
      "Procesando lote 42/185...\n",
      "Quedan 143 lotes.\n",
      "Procesando lote 43/185...\n",
      "Quedan 142 lotes.\n",
      "Procesando lote 44/185...\n",
      "Quedan 141 lotes.\n",
      "Procesando lote 45/185...\n",
      "Quedan 140 lotes.\n",
      "Procesando lote 46/185...\n",
      "Quedan 139 lotes.\n",
      "Procesando lote 47/185...\n",
      "Quedan 138 lotes.\n",
      "Procesando lote 48/185...\n",
      "Quedan 137 lotes.\n",
      "Procesando lote 49/185...\n",
      "Quedan 136 lotes.\n",
      "Procesando lote 50/185...\n",
      "Quedan 135 lotes.\n",
      "Procesando lote 51/185...\n",
      "Quedan 134 lotes.\n",
      "Procesando lote 52/185...\n",
      "Quedan 133 lotes.\n",
      "Procesando lote 53/185...\n",
      "Quedan 132 lotes.\n",
      "Procesando lote 54/185...\n",
      "Quedan 131 lotes.\n",
      "Procesando lote 55/185...\n",
      "Quedan 130 lotes.\n",
      "Procesando lote 56/185...\n",
      "Quedan 129 lotes.\n",
      "Procesando lote 57/185...\n",
      "Quedan 128 lotes.\n",
      "Procesando lote 58/185...\n",
      "Quedan 127 lotes.\n",
      "Procesando lote 59/185...\n",
      "Quedan 126 lotes.\n",
      "Procesando lote 60/185...\n",
      "Quedan 125 lotes.\n",
      "Procesando lote 61/185...\n",
      "Quedan 124 lotes.\n",
      "Procesando lote 62/185...\n",
      "Quedan 123 lotes.\n",
      "Procesando lote 63/185...\n",
      "Quedan 122 lotes.\n",
      "Procesando lote 64/185...\n",
      "Quedan 121 lotes.\n",
      "Procesando lote 65/185...\n",
      "Quedan 120 lotes.\n",
      "Procesando lote 66/185...\n",
      "Quedan 119 lotes.\n",
      "Procesando lote 67/185...\n",
      "Quedan 118 lotes.\n",
      "Procesando lote 68/185...\n",
      "Quedan 117 lotes.\n",
      "Procesando lote 69/185...\n",
      "Quedan 116 lotes.\n",
      "Procesando lote 70/185...\n",
      "Quedan 115 lotes.\n",
      "Procesando lote 71/185...\n",
      "Quedan 114 lotes.\n",
      "Procesando lote 72/185...\n",
      "Quedan 113 lotes.\n",
      "Procesando lote 73/185...\n",
      "Quedan 112 lotes.\n",
      "Procesando lote 74/185...\n",
      "Quedan 111 lotes.\n",
      "Procesando lote 75/185...\n",
      "Quedan 110 lotes.\n",
      "Procesando lote 76/185...\n",
      "Quedan 109 lotes.\n",
      "Procesando lote 77/185...\n",
      "Quedan 108 lotes.\n",
      "Procesando lote 78/185...\n",
      "Quedan 107 lotes.\n",
      "Procesando lote 79/185...\n",
      "Quedan 106 lotes.\n",
      "Procesando lote 80/185...\n",
      "Quedan 105 lotes.\n",
      "Procesando lote 81/185...\n",
      "Quedan 104 lotes.\n",
      "Procesando lote 82/185...\n",
      "Quedan 103 lotes.\n",
      "Procesando lote 83/185...\n",
      "Quedan 102 lotes.\n",
      "Procesando lote 84/185...\n",
      "Quedan 101 lotes.\n",
      "Procesando lote 85/185...\n",
      "Quedan 100 lotes.\n",
      "Procesando lote 86/185...\n",
      "Quedan 99 lotes.\n",
      "Procesando lote 87/185...\n",
      "Quedan 98 lotes.\n",
      "Procesando lote 88/185...\n",
      "Quedan 97 lotes.\n",
      "Procesando lote 89/185...\n",
      "Quedan 96 lotes.\n",
      "Procesando lote 90/185...\n",
      "Quedan 95 lotes.\n",
      "Procesando lote 91/185...\n",
      "Quedan 94 lotes.\n",
      "Procesando lote 92/185...\n",
      "Quedan 93 lotes.\n",
      "Procesando lote 93/185...\n",
      "Quedan 92 lotes.\n",
      "Procesando lote 94/185...\n",
      "Quedan 91 lotes.\n",
      "Procesando lote 95/185...\n",
      "Quedan 90 lotes.\n",
      "Procesando lote 96/185...\n",
      "Quedan 89 lotes.\n",
      "Procesando lote 97/185...\n",
      "Quedan 88 lotes.\n",
      "Procesando lote 98/185...\n",
      "Quedan 87 lotes.\n",
      "Procesando lote 99/185...\n",
      "Quedan 86 lotes.\n",
      "Procesando lote 100/185...\n",
      "Quedan 85 lotes.\n",
      "Procesando lote 101/185...\n",
      "Quedan 84 lotes.\n",
      "Procesando lote 102/185...\n",
      "Quedan 83 lotes.\n",
      "Procesando lote 103/185...\n",
      "Quedan 82 lotes.\n",
      "Procesando lote 104/185...\n",
      "Quedan 81 lotes.\n",
      "Procesando lote 105/185...\n",
      "Quedan 80 lotes.\n",
      "Procesando lote 106/185...\n",
      "Quedan 79 lotes.\n",
      "Procesando lote 107/185...\n",
      "Quedan 78 lotes.\n",
      "Procesando lote 108/185...\n",
      "Quedan 77 lotes.\n",
      "Procesando lote 109/185...\n",
      "Quedan 76 lotes.\n",
      "Procesando lote 110/185...\n",
      "Quedan 75 lotes.\n",
      "Procesando lote 111/185...\n",
      "Quedan 74 lotes.\n",
      "Procesando lote 112/185...\n",
      "Quedan 73 lotes.\n",
      "Procesando lote 113/185...\n",
      "Quedan 72 lotes.\n",
      "Procesando lote 114/185...\n",
      "Quedan 71 lotes.\n",
      "Procesando lote 115/185...\n",
      "Quedan 70 lotes.\n",
      "Procesando lote 116/185...\n",
      "Quedan 69 lotes.\n",
      "Procesando lote 117/185...\n",
      "Quedan 68 lotes.\n",
      "Procesando lote 118/185...\n",
      "Quedan 67 lotes.\n",
      "Procesando lote 119/185...\n",
      "Quedan 66 lotes.\n",
      "Procesando lote 120/185...\n",
      "Quedan 65 lotes.\n",
      "Procesando lote 121/185...\n",
      "Quedan 64 lotes.\n",
      "Procesando lote 122/185...\n",
      "Quedan 63 lotes.\n",
      "Procesando lote 123/185...\n",
      "Quedan 62 lotes.\n",
      "Procesando lote 124/185...\n",
      "Quedan 61 lotes.\n",
      "Procesando lote 125/185...\n",
      "Quedan 60 lotes.\n",
      "Procesando lote 126/185...\n",
      "Quedan 59 lotes.\n",
      "Procesando lote 127/185...\n",
      "Quedan 58 lotes.\n",
      "Procesando lote 128/185...\n",
      "Quedan 57 lotes.\n",
      "Procesando lote 129/185...\n",
      "Quedan 56 lotes.\n",
      "Procesando lote 130/185...\n",
      "Quedan 55 lotes.\n",
      "Procesando lote 131/185...\n",
      "Quedan 54 lotes.\n",
      "Procesando lote 132/185...\n",
      "Quedan 53 lotes.\n",
      "Procesando lote 133/185...\n",
      "Quedan 52 lotes.\n",
      "Procesando lote 134/185...\n",
      "Quedan 51 lotes.\n",
      "Procesando lote 135/185...\n",
      "Quedan 50 lotes.\n",
      "Procesando lote 136/185...\n",
      "Quedan 49 lotes.\n",
      "Procesando lote 137/185...\n",
      "Quedan 48 lotes.\n",
      "Procesando lote 138/185...\n",
      "Quedan 47 lotes.\n",
      "Procesando lote 139/185...\n",
      "Quedan 46 lotes.\n",
      "Procesando lote 140/185...\n",
      "Quedan 45 lotes.\n",
      "Procesando lote 141/185...\n",
      "Quedan 44 lotes.\n",
      "Procesando lote 142/185...\n",
      "Quedan 43 lotes.\n",
      "Procesando lote 143/185...\n",
      "Quedan 42 lotes.\n",
      "Procesando lote 144/185...\n",
      "Quedan 41 lotes.\n",
      "Procesando lote 145/185...\n",
      "Quedan 40 lotes.\n",
      "Procesando lote 146/185...\n",
      "Quedan 39 lotes.\n",
      "Procesando lote 147/185...\n",
      "Quedan 38 lotes.\n",
      "Procesando lote 148/185...\n",
      "Quedan 37 lotes.\n",
      "Procesando lote 149/185...\n",
      "Quedan 36 lotes.\n",
      "Procesando lote 150/185...\n",
      "Quedan 35 lotes.\n",
      "Procesando lote 151/185...\n",
      "Quedan 34 lotes.\n",
      "Procesando lote 152/185...\n",
      "Quedan 33 lotes.\n",
      "Procesando lote 153/185...\n",
      "Quedan 32 lotes.\n",
      "Procesando lote 154/185...\n",
      "Quedan 31 lotes.\n",
      "Procesando lote 155/185...\n",
      "Quedan 30 lotes.\n",
      "Procesando lote 156/185...\n",
      "Quedan 29 lotes.\n",
      "Procesando lote 157/185...\n",
      "Quedan 28 lotes.\n",
      "Procesando lote 158/185...\n",
      "Quedan 27 lotes.\n",
      "Procesando lote 159/185...\n",
      "Quedan 26 lotes.\n",
      "Procesando lote 160/185...\n",
      "Quedan 25 lotes.\n",
      "Procesando lote 161/185...\n",
      "Quedan 24 lotes.\n",
      "Procesando lote 162/185...\n",
      "Quedan 23 lotes.\n",
      "Procesando lote 163/185...\n",
      "Quedan 22 lotes.\n",
      "Procesando lote 164/185...\n",
      "Quedan 21 lotes.\n",
      "Procesando lote 165/185...\n",
      "Quedan 20 lotes.\n",
      "Procesando lote 166/185...\n",
      "Quedan 19 lotes.\n",
      "Procesando lote 167/185...\n",
      "Quedan 18 lotes.\n",
      "Procesando lote 168/185...\n",
      "Quedan 17 lotes.\n",
      "Procesando lote 169/185...\n",
      "Quedan 16 lotes.\n",
      "Procesando lote 170/185...\n",
      "Quedan 15 lotes.\n",
      "Procesando lote 171/185...\n",
      "Quedan 14 lotes.\n",
      "Procesando lote 172/185...\n",
      "Quedan 13 lotes.\n",
      "Procesando lote 173/185...\n",
      "Quedan 12 lotes.\n",
      "Procesando lote 174/185...\n",
      "Quedan 11 lotes.\n",
      "Procesando lote 175/185...\n",
      "Quedan 10 lotes.\n",
      "Procesando lote 176/185...\n",
      "Quedan 9 lotes.\n",
      "Procesando lote 177/185...\n",
      "Quedan 8 lotes.\n",
      "Procesando lote 178/185...\n",
      "Quedan 7 lotes.\n",
      "Procesando lote 179/185...\n",
      "Quedan 6 lotes.\n",
      "Procesando lote 180/185...\n",
      "Quedan 5 lotes.\n",
      "Procesando lote 181/185...\n",
      "Quedan 4 lotes.\n",
      "Procesando lote 182/185...\n",
      "Quedan 3 lotes.\n",
      "Procesando lote 183/185...\n",
      "Quedan 2 lotes.\n",
      "Procesando lote 184/185...\n",
      "Quedan 1 lotes.\n",
      "Procesando lote 185/185...\n",
      "Quedan 0 lotes.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_batches = len(dataloader)  # Número total de lotes\n",
    "    for batch_idx, (images, seq_len, labels) in enumerate(dataloader):\n",
    "        print(f\"Procesando lote {batch_idx + 1}/{total_batches}...\")\n",
    "\n",
    "        output = model(images)\n",
    "\n",
    "        # Aplicamos el umbral de 0.5 y convertimos a int\n",
    "        predicted = (output > 0.5).int()\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        remaining_batches = total_batches - (batch_idx + 1)\n",
    "        print(f\"Quedan {remaining_batches} lotes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81        62\n",
      "           1       0.89      0.94      0.91       123\n",
      "\n",
      "    accuracy                           0.88       185\n",
      "   macro avg       0.88      0.85      0.86       185\n",
      "weighted avg       0.88      0.88      0.88       185\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Patient ID  BIRADS  malignant\n",
      "70   AMBL-071       4          1\n"
     ]
    }
   ],
   "source": [
    "random_row = df_subset.sample(n=1) \n",
    "\n",
    "print(random_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BreastCancerPredictionDataset(Dataset):\n",
    "    def __init__(self, patient_id, root_dir, max_images=116, image_size=224, transform=None):\n",
    "        self.patient_id = patient_id\n",
    "        self.root_dir = root_dir\n",
    "        self.max_images = max_images\n",
    "        self.image_size = image_size\n",
    "        self.transform = transform\n",
    "        self.to_pil = ToPILImage()\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.patient_id\n",
    "        patient_dir = os.path.join(self.root_dir, patient_id)\n",
    "        \n",
    "        dicom_files = sorted([f for f in os.listdir(patient_dir) if f.endswith('.dcm')])\n",
    "\n",
    "        images = []\n",
    "        for file in dicom_files[:self.max_images]:\n",
    "            image_path = os.path.join(patient_dir, file)\n",
    "            image = load_dicom_image(image_path) \n",
    "            if image is not None:\n",
    "                image = normalize_for_resnet(image)\n",
    "                image = self.to_pil(image)\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "                \n",
    "                images.append(image)\n",
    "\n",
    "        sequence_length = len(images)\n",
    "\n",
    "        if len(images) == 0:\n",
    "            placeholder_image = torch.zeros((3, self.image_size, self.image_size))\n",
    "            images = [placeholder_image] * self.max_images\n",
    "        while len(images) < self.max_images:\n",
    "            images.append(torch.zeros_like(images[0]))\n",
    "\n",
    "        images_tensor = torch.stack(images)\n",
    "        return images_tensor, sequence_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción para el paciente AMBL-071: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_single_patient(patient_id, model, root_dir, transform=None):\n",
    "\n",
    "    dataset_single_patient = BreastCancerPredictionDataset(patient_id, root_dir, transform=transform)\n",
    "\n",
    "    dataloader_single_patient = DataLoader(dataset_single_patient, batch_size=1)\n",
    "\n",
    "    model.eval() \n",
    "    with torch.no_grad(): \n",
    "        for images, _ in dataloader_single_patient:\n",
    "            images = images.to(device) \n",
    "            outputs = model(images)\n",
    "            predicted = (outputs > 0.5).int() \n",
    "    return predicted[0].item() \n",
    "\n",
    "\n",
    "patient_id = random_row[\"Patient ID\"].item() \n",
    "prediction = predict_single_patient(patient_id, model, dataDirectory, transform=test_transform)\n",
    "\n",
    "print(f'Predicción para el paciente {patient_id}: {prediction}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model_f1_0.7682.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
